{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16543474-7981-459f-9567-0c977d917b79",
   "metadata": {},
   "source": [
    "# Stemming:\n",
    "Stemming removes common suffixes from end of word tokens\n",
    "\n",
    "ex. Boating --- boat is a stem of boating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab33f07b-7cb9-45d1-92fc-8c5c36899741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the nltk package\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494b8dae-c2b4-4e6d-b015-abd34e5173c6",
   "metadata": {},
   "source": [
    "Natural Language Toolkit (NLTK) is a suite of libraries and programs for symbolic and statistical natural language processing for English, written in the Python programming language.\n",
    "NLTK also supports classification, tokenization, stemming, tagging, parsing, sematic and reasoning functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da90767-cf9f-4ef3-82dd-40f9491f9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the libraries from the NLTK package\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53883a0-747f-4dde-92cf-084823b0aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing PorterStemmer, an algorithm used for stemming words in natural language processing\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432d11fd-e2a4-4809-8fee-9d55792c678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list, of words\n",
    "the_words = ['run','runner','running','runs','ran','runnable','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad0592e-9134-4835-a1d0-f80e50148bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run --- run\n",
      "runner --- runner\n",
      "running --- run\n",
      "runs --- run\n",
      "ran --- ran\n",
      "runnable --- runnabl\n",
      "fairly --- fairli\n"
     ]
    }
   ],
   "source": [
    "#using for loop to print the stem of each word, from the 'list of words\n",
    "for word in the_words:\n",
    "    print(f\"{word} --- {p_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff42e436-8eaa-4c57-a59e-d32d66c4b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing SnowballStemmer from the Nltk package\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "314bb6a8-7c5b-4fec-ad02-169ba26dad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming an English word\n",
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c5a4a9-9835-43d4-a2ae-b28713519f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating another list of words\n",
    "the_wordss = ['run','runner','running','runs','ran','runnable','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "867555fb-5f3a-4b1b-b658-3dda4c5ea86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run --- run\n",
      "runner --- runner\n",
      "running --- run\n",
      "runs --- run\n",
      "ran --- ran\n",
      "runnable --- runnabl\n",
      "fairly --- fair\n"
     ]
    }
   ],
   "source": [
    "#using for loop, printing the stemmed word for each word in the list\n",
    "for word in the_wordss:\n",
    "    print(f\"{word} --- {s_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca96377-2263-469b-95d8-08d6bd7d1c99",
   "metadata": {},
   "source": [
    "# Lemmatization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c23e5a-ae15-4bce-a655-aef9b39ad7a5",
   "metadata": {},
   "source": [
    "Lemmatization ensures that the output word is an existing, normalised form of word\n",
    "\n",
    "ex. was --- be\n",
    "\n",
    "mice --- mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a105b8d-5bcc-4b28-912e-1cc836e3a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the spacy module\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5082fff-646a-4350-a731-a19e3b02bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the English language model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34a10d2b-80cb-4dce-b6b5-b62d9b2638d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing an English sentence\n",
    "doc_1 = nlp(\"I am a runner running in a running race because I love to run, and since I ran today.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cc2fc99-32ec-40cb-9a6e-c7f371e416f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 4690420944186131903 \t I\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "because \t SCONJ \t 16950148841647037698 \t because\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "run \t VERB \t 12767647472892411841 \t run\n",
      ", \t PUNCT \t 2593208677638477497 \t ,\n",
      "and \t CCONJ \t 2283656566040971221 \t and\n",
      "since \t SCONJ \t 10066841407251338481 \t since\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      "today \t NOUN \t 11042482332948150395 \t today\n",
      ". \t PUNCT \t 12646065887601541794 \t .\n"
     ]
    }
   ],
   "source": [
    "#using for loop, printing each token from the English sentence along with its part of speech and dependency, after performing tokenization\n",
    "for token in doc_1:\n",
    "    print(token.text, \"\\t\", token.pos_, \"\\t\", token.lemma, \"\\t\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec3b7c3e-7677-4530-8026-448be8141c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function that will show is lemmatized word of another English word\n",
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c9e9afc-5030-49b7-a9b0-0d8dba442bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_2 = nlp('I saw twenty mice today.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2c8cf56-7eb3-4439-ba3e-5022b1776e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   4690420944186131903    I\n",
      "saw          VERB   11925638236994514241   see\n",
      "twenty       NUM    8304598090389628520    twenty\n",
      "mice         NOUN   1384165645700560590    mouse\n",
      "today        NOUN   11042482332948150395   today\n",
      ".            PUNCT  12646065887601541794   .\n"
     ]
    }
   ],
   "source": [
    "show_lemmas(doc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180521d-da49-4950-b58e-e7121f0ffee4",
   "metadata": {},
   "source": [
    "# Stop Words:\n",
    "Stop words are a collection of commonly used words in English language.\n",
    "\n",
    "Stop words are most widely used in text mining and NLP to eliminate words that are often used, that they carry very little useful information.\n",
    "\n",
    "ex. A, The"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00698c13-b0d6-4693-8efc-fb0b431fe0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the spacy module and loading the English language model\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ba6adee-3697-49de-81eb-61076cd30ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'also', 'at', 'fifteen', 'move', 'else', 'somehow', 'because', 'how', 'sixty', 'ever', 'always', 'had', 'sometime', 'someone', 'toward', 'on', 'anyone', 'seem', 'for', 'become', 'besides', 'could', 'among', 'they', 'anyway', 'so', 'nowhere', 'well', 'mostly', 'out', \"'d\", 'each', 'except', 'hereafter', 'rather', 'put', 'still', 'perhaps', 'keep', 'together', 'does', 'just', 'almost', 'without', 'whose', 'here', 'and', 'throughout', 'namely', 'anywhere', '‘d', 'full', 'back', 'against', 'less', 'very', 'seeming', 'thereupon', 'nobody', 'only', 'anything', 'third', 'whence', 'becoming', 'do', 'from', 'us', '’re', 'again', 'herself', 'his', 'has', 'everywhere', '‘m', 'twelve', 'upon', 'when', 'several', 'seems', 'across', 'enough', 'otherwise', 'hundred', 'after', 'she', 'make', 'everything', 'is', 'really', '’ve', 'thus', 'yours', 'amongst', 'whether', 'own', 'sometimes', 'during', 'been', 'may', 'twenty', 'noone', 'cannot', \"'ll\", 'ourselves', 'name', 'more', 'former', 'beside', 'everyone', 'should', 'whereafter', 'top', 'before', 'no', 'which', 'please', 'most', 'becomes', 'over', 'too', \"'ve\", 'myself', 'of', 'the', 'by', 'both', 'all', 'another', 'it', 'nine', 'above', 'any', 'n‘t', 'what', 'give', 'into', 'will', '’d', 'whereupon', 'who', 'none', '‘ve', 'wherein', 'an', 'afterwards', 'go', 'you', 'through', 'either', 'mine', 'him', 'as', 'that', 'five', 'much', 'often', 'onto', 'was', 'whole', '‘re', 'in', 'latterly', 'take', 'me', 'further', 'however', 'some', 'amount', 'whereas', 'became', 'moreover', 'did', 'whoever', 'ten', 'other', 'than', 'every', 'them', 'say', 'were', 'various', 'few', 'anyhow', 'along', 'ours', 'see', 'made', 'our', 'or', 'would', 'whenever', 'yourselves', 'somewhere', 'her', 'four', 'least', 'to', 'below', 'nevertheless', 'he', 'nor', 'might', 'elsewhere', 'forty', 'serious', 'not', 'part', 'latter', 'call', 'neither', 'others', 're', 'wherever', 'since', 'but', 'though', '’s', 'whatever', 'due', 'front', 'never', 'eight', 'show', \"'re\", 'my', 'herein', 'meanwhile', 'beforehand', 'formerly', 'hers', 'something', 'whereby', 'using', 'per', 'are', 'hereupon', 'whom', 'while', 'hereby', 'thence', '‘ll', 'towards', 'your', 'until', 'unless', 'whither', 'a', 'fifty', 'can', 'if', 'himself', 'three', 'their', 'empty', 'between', 'its', 'this', 'one', 'ca', 'around', 'down', 'with', 'these', 'n’t', 'although', 'those', 'last', 'side', 'then', 'such', 'yet', 'therein', '’ll', 'there', 'be', 'two', 'seemed', 'even', '’m', 'behind', 'where', 'hence', 'many', 'thereby', 'used', 'why', 'itself', 'up', 'eleven', 'via', 'done', 'we', 'quite', 'get', 'beyond', 'first', \"n't\", 'being', 'regarding', 'bottom', \"'s\", 'i', 'six', 'within', '‘s', 'alone', 'doing', 'now', 'already', \"'m\", 'yourself', 'same', 'about', 'therefore', 'nothing', 'thereafter', 'indeed', 'must', 'themselves', 'thru', 'under', 'once', 'next', 'off', 'am', 'have'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1cc1820-49f6-4eea-9faf-bd984b931e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if a word is a stop word\n",
    "nlp.vocab['myself'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cb64e9b-b4f5-42f0-a916-a1388063a64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['although'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1cd3f6b-4b97-4d03-a9b5-6c6250dd810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the word 'urselves' onto the list of all stop words in English language\n",
    "nlp.Defaults.stop_words.add('urselves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "328f91dd-fea1-4830-a1c4-48e5ec207357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['urselves'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6af95585-170a-415a-b3f4-a8e465817d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'also', 'at', 'fifteen', 'move', 'else', 'somehow', 'because', 'how', 'sixty', 'ever', 'always', 'had', 'sometime', 'someone', 'toward', 'on', 'anyone', 'seem', 'for', 'become', 'besides', 'could', 'among', 'they', 'anyway', 'so', 'nowhere', 'well', 'mostly', 'out', \"'d\", 'each', 'except', 'hereafter', 'rather', 'put', 'still', 'perhaps', 'keep', 'together', 'does', 'just', 'almost', 'without', 'whose', 'here', 'and', 'throughout', 'namely', 'anywhere', '‘d', 'full', 'back', 'against', 'less', 'very', 'seeming', 'thereupon', 'nobody', 'only', 'anything', 'third', 'whence', 'becoming', 'urselves', 'do', 'from', 'us', '’re', 'again', 'herself', 'his', 'has', 'everywhere', '‘m', 'twelve', 'upon', 'when', 'several', 'seems', 'across', 'enough', 'otherwise', 'hundred', 'after', 'she', 'make', 'everything', 'is', 'really', '’ve', 'thus', 'yours', 'amongst', 'whether', 'own', 'sometimes', 'during', 'been', 'may', 'twenty', 'noone', 'cannot', \"'ll\", 'ourselves', 'name', 'more', 'former', 'beside', 'everyone', 'should', 'whereafter', 'top', 'before', 'no', 'which', 'please', 'most', 'becomes', 'over', 'too', \"'ve\", 'myself', 'of', 'the', 'by', 'both', 'all', 'another', 'it', 'nine', 'above', 'any', 'n‘t', 'what', 'give', 'into', 'will', '’d', 'whereupon', 'who', 'none', '‘ve', 'wherein', 'an', 'afterwards', 'go', 'you', 'through', 'either', 'mine', 'him', 'as', 'that', 'five', 'much', 'often', 'onto', 'was', 'whole', '‘re', 'in', 'latterly', 'take', 'me', 'further', 'however', 'some', 'amount', 'whereas', 'became', 'moreover', 'did', 'whoever', 'ten', 'other', 'than', 'every', 'them', 'say', 'were', 'various', 'few', 'anyhow', 'along', 'ours', 'see', 'made', 'our', 'or', 'would', 'whenever', 'yourselves', 'somewhere', 'her', 'four', 'least', 'to', 'below', 'nevertheless', 'he', 'nor', 'might', 'elsewhere', 'forty', 'serious', 'not', 'part', 'latter', 'call', 'neither', 'others', 're', 'wherever', 'since', 'but', 'though', '’s', 'whatever', 'due', 'front', 'never', 'eight', 'show', \"'re\", 'my', 'herein', 'meanwhile', 'beforehand', 'formerly', 'hers', 'something', 'whereby', 'using', 'per', 'are', 'hereupon', 'whom', 'while', 'hereby', 'thence', '‘ll', 'towards', 'your', 'until', 'unless', 'whither', 'a', 'fifty', 'can', 'if', 'himself', 'three', 'their', 'empty', 'between', 'its', 'this', 'one', 'ca', 'around', 'down', 'with', 'these', 'n’t', 'although', 'those', 'last', 'side', 'then', 'such', 'yet', 'therein', '’ll', 'there', 'be', 'two', 'seemed', 'even', '’m', 'behind', 'where', 'hence', 'many', 'thereby', 'used', 'why', 'itself', 'up', 'eleven', 'via', 'done', 'we', 'quite', 'get', 'beyond', 'first', \"n't\", 'being', 'regarding', 'bottom', \"'s\", 'i', 'six', 'within', '‘s', 'alone', 'doing', 'now', 'already', \"'m\", 'yourself', 'same', 'about', 'therefore', 'nothing', 'thereafter', 'indeed', 'must', 'themselves', 'thru', 'under', 'once', 'next', 'off', 'am', 'have'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4980a-b7bb-43c2-b04a-afa5ae97b974",
   "metadata": {},
   "source": [
    "The word 'urselves' is now added onto the list of stop words in English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325eb0a-4e03-48b5-aabc-bf8f57f5f1be",
   "metadata": {},
   "source": [
    "Similarly, the word can also be removed from the list stop words in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f96c1bff-f4bd-471a-95b0-9bdb217379eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.remove('urselves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "271ccfbf-2a3b-450a-937c-46f8ada2319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'also', 'at', 'fifteen', 'move', 'else', 'somehow', 'because', 'how', 'sixty', 'ever', 'always', 'had', 'sometime', 'someone', 'toward', 'on', 'anyone', 'seem', 'for', 'become', 'besides', 'could', 'among', 'they', 'anyway', 'so', 'nowhere', 'well', 'mostly', 'out', \"'d\", 'each', 'except', 'hereafter', 'rather', 'put', 'still', 'perhaps', 'keep', 'together', 'does', 'just', 'almost', 'without', 'whose', 'here', 'and', 'throughout', 'namely', 'anywhere', '‘d', 'full', 'back', 'against', 'less', 'very', 'seeming', 'thereupon', 'nobody', 'only', 'anything', 'third', 'whence', 'becoming', 'do', 'from', 'us', '’re', 'again', 'herself', 'his', 'has', 'everywhere', '‘m', 'twelve', 'upon', 'when', 'several', 'seems', 'across', 'enough', 'otherwise', 'hundred', 'after', 'she', 'make', 'everything', 'is', 'really', '’ve', 'thus', 'yours', 'amongst', 'whether', 'own', 'sometimes', 'during', 'been', 'may', 'twenty', 'noone', 'cannot', \"'ll\", 'ourselves', 'name', 'more', 'former', 'beside', 'everyone', 'should', 'whereafter', 'top', 'before', 'no', 'which', 'please', 'most', 'becomes', 'over', 'too', \"'ve\", 'myself', 'of', 'the', 'by', 'both', 'all', 'another', 'it', 'nine', 'above', 'any', 'n‘t', 'what', 'give', 'into', 'will', '’d', 'whereupon', 'who', 'none', '‘ve', 'wherein', 'an', 'afterwards', 'go', 'you', 'through', 'either', 'mine', 'him', 'as', 'that', 'five', 'much', 'often', 'onto', 'was', 'whole', '‘re', 'in', 'latterly', 'take', 'me', 'further', 'however', 'some', 'amount', 'whereas', 'became', 'moreover', 'did', 'whoever', 'ten', 'other', 'than', 'every', 'them', 'say', 'were', 'various', 'few', 'anyhow', 'along', 'ours', 'see', 'made', 'our', 'or', 'would', 'whenever', 'yourselves', 'somewhere', 'her', 'four', 'least', 'to', 'below', 'nevertheless', 'he', 'nor', 'might', 'elsewhere', 'forty', 'serious', 'not', 'part', 'latter', 'call', 'neither', 'others', 're', 'wherever', 'since', 'but', 'though', '’s', 'whatever', 'due', 'front', 'never', 'eight', 'show', \"'re\", 'my', 'herein', 'meanwhile', 'beforehand', 'formerly', 'hers', 'something', 'whereby', 'using', 'per', 'are', 'hereupon', 'whom', 'while', 'hereby', 'thence', '‘ll', 'towards', 'your', 'until', 'unless', 'whither', 'a', 'fifty', 'can', 'if', 'himself', 'three', 'their', 'empty', 'between', 'its', 'this', 'one', 'ca', 'around', 'down', 'with', 'these', 'n’t', 'although', 'those', 'last', 'side', 'then', 'such', 'yet', 'therein', '’ll', 'there', 'be', 'two', 'seemed', 'even', '’m', 'behind', 'where', 'hence', 'many', 'thereby', 'used', 'why', 'itself', 'up', 'eleven', 'via', 'done', 'we', 'quite', 'get', 'beyond', 'first', \"n't\", 'being', 'regarding', 'bottom', \"'s\", 'i', 'six', 'within', '‘s', 'alone', 'doing', 'now', 'already', \"'m\", 'yourself', 'same', 'about', 'therefore', 'nothing', 'thereafter', 'indeed', 'must', 'themselves', 'thru', 'under', 'once', 'next', 'off', 'am', 'have'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
